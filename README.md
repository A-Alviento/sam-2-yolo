# Sam2Yolo-Tool
**NOTE: This branch is specifically for apple silicon. This branch is specifically tested and run using Python 3.8 on a Macbook Air using M1 apple silicon**
This project leverages the capabilities of the Segment Anything Model (SAM) to automate the process of creating segmentation datasets for YOLOv8.

## Description

This tool, as outlined in `notebooks/bbox-idea.ipynb`, facilitates the effortless annotation of segmentation datasets. Users can inspect images and manually delineate bounding boxes around objects they aim to segment. These bounding boxes serve as the input for the Segment Anything Model (SAM).

The Python widget in the tool dynamically displays the output generated by SAM, creating an interactive and real-time experience for the user. Additionally, the tool allows users to categorize each segment according to predefined classes, contributing to the organization and classification of the segmentation dataset.

## Running the program

- To get started, make the following directory `sam-2-yolo/1-source` and place the videos you want to use as a dataset.
    - Alternatively, if you already have a set of images, simply place your images into directory `sam-2-yolo/2-source-extracted` **NOTE: Only .png is supported currently**
- Open the notebook and follow the installation process and the subsequent instructions for running

### Future Plans:
- Short-term:
    - Support more image type
    - A short-term implementation of deploying to a local web-app (using something like streamlit for e.g.) for a better user interface
    - Further optimization of functions
- Long-term
    - Transform the notebook into a full fledge web-app

## Acknowledgements

This project was inspired by and made possible through the following resources:

- [Segment Anything Model (SAM) by Facebook Research](https://github.com/facebookresearch/segment-anything/blob/main/README.md)
- [Ultralytics YOLO](https://github.com/ultralytics/yolov5)
